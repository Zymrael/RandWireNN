data:
  train: ''
  val: ''
  batch_size: 128 # for test, batch_size//8 will be used.
  num_workers: 16
---
train:
  optimizer: 'adam'
  adam: 0.001
  adabound:
    initial: 0.001
    final: 0.05
  sgd:
    lr: 0.1
    momentum: 0.9
    weight_decay: 0.00005
  decay:
    step: 150000
    gamma: 0.1
  summary_interval: 1
  checkpoint_interval: 1000
  evaluation_interval: 1000
---
model:
  channel: 78 # 'small regime'
  classes: 1000
  graph0: '' # example: 'ws-4-075-3.txt'
  graph1: ''
  graph2: ''
---
log:
  chkpt_dir: 'chkpt'
  log_dir: 'logs'
