data:
  train: 'download'
  val: 'download'
  batch_size: 128 # for test, batch_size//8 will be used.
  num_workers: 16
  type: 'MNIST'
---
train:
  optimizer: 'adam'
  adam: 0.001
  adabound:
    initial: 0.001
    final: 0.05
  decay:
    step: 150000
    gamma: 0.1
  summary_interval: 1
  checkpoint_interval: 1000
  evaluation_interval: 1000
---
model:
  channel: 78 # 'small regime'
  classes: 10
  input_maps: 1
  graph0: 'ws-4-075-3.txt'
  graph1: 'ws-4-075-4.txt'
  graph2: 'ws-4-075-5.txt'
---
log:
  chkpt_dir: 'chkpt'
  log_dir: 'logs'
